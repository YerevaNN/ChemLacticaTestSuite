{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import torch\n",
    "from accelerate import init_empty_weights, Accelerator\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from custom_modeling_opt import CustomOPTForCausalLM\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value=42\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit.Chem as Chem\n",
    "import sys\n",
    "from rdkit.Chem import RDConfig, MACCSkeys, QED\n",
    "from rdkit.Chem.rdMolDescriptors import CalcTPSA, CalcCrippenDescriptors\n",
    "from rdkit.Chem import Descriptors\n",
    "sys.path.append(os.path.join(RDConfig.RDContribDir, 'SA_Score'))\n",
    "import sascorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer size:  50066\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/auto/home/menuab/code/ChemLacticaTestSuite/src/tokenizer/ChemLacticaTokenizer_50066/\")\n",
    "print('tokenizer size: ', len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/auto/home/menuab/code/checkpoints/26d322857a184fcbafda5d4a/125m_118k_26d3/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"/auto/home/menuab/code/checkpoints/f2c6ebb289994595a478f513/125m_126k_f2c6/\"\n",
    "checkpoint_path = \"/auto/home/menuab/code/checkpoints/f3fbd012918247a388efa732/125m_126k_f3fb/\"\n",
    "checkpoint_path = \"/auto/home/menuab/code/checkpoints/26d322857a184fcbafda5d4a/125m_118k_26d3/\"\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded with embedding size of : 50066\n"
     ]
    }
   ],
   "source": [
    "model = CustomOPTForCausalLM.from_pretrained(\n",
    "            checkpoint_path,\n",
    "            use_flash_attn=True,\n",
    "            torch_dtype=torch.bfloat16\n",
    "            )\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f'model loaded with embedding size of : {model.model.decoder.embed_tokens.num_embeddings}')\n",
    "assert(model.model.decoder.embed_tokens.num_embeddings == len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tanimoto_distance(smiles1, smiles2):\n",
    "    # Convert SMILES strings to RDKit molecules\n",
    "    mol1 = Chem.MolFromSmiles(smiles1)\n",
    "    mol2 = Chem.MolFromSmiles(smiles2)\n",
    "    \n",
    "    # Check if the molecules were successfully created\n",
    "    if mol1 is None or mol2 is None:\n",
    "        raise ValueError(\"Invalid SMILES representation\")\n",
    "\n",
    "    # Generate MACCS keys for the molecules\n",
    "    keys1 = MACCSkeys.GenMACCSKeys(mol1)\n",
    "    keys2 = MACCSkeys.GenMACCSKeys(mol2)\n",
    "\n",
    "    # Calculate the Tanimoto similarity\n",
    "    common_bits = sum(bit1 & bit2 for bit1, bit2 in zip(keys1, keys2))\n",
    "    total_bits = sum(bit1 | bit2 for bit1, bit2 in zip(keys1, keys2))\n",
    "\n",
    "    tanimoto_distance = 1.0 - (common_bits / total_bits)  # Tanimoto distance ranges from 0 to 1\n",
    "\n",
    "    return tanimoto_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = ['COc1ccccc1NS(=O)(=O)c1ccc(NC(C)=O)cc1',\n",
    "'CC(=O)Oc1cc2oc(=O)cc(C)c2cc1OC(C)=O',\n",
    "'COc1ccc(Oc2coc3cc(OC(C)=O)ccc3c2=O)cc1',\n",
    "'COc1ccc(C(=O)OCC(=O)Nc2ccc(C)cc2)cc1OC',\n",
    "'COc1ccc(C(=O)OCC(=O)Nc2ccc(F)cc2)cc1OC',\n",
    "'COc1ccc(C(=O)OCC(=O)Nc2ccc(Cl)cc2)cc1OC',\n",
    "'COc1ccc(OC)c(-c2oc3ccccc3c(=O)c2O)c1',\n",
    "'O=S(=O)(NCc1ccc(F)cc1F)c1ccc(F)cc1F',\n",
    "'CC1(O)CCC2C3CCC4=C(CCC(=O)C4)C3CCC21C',\n",
    "'NS(=O)(=O)c1cc(C(=O)Nc2ccccc2Cl)ccc1F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'[SIMILAR]{mols[0]} 0.9[/SIMILAR][START_SMILES]'\n",
    "\n",
    "# prompt = f'[SIMILAR]CC(=O)NC1=CC=C(C=C1)S(=O)(=O)NC2=CC=CC=C2OC 0.9[/SIMILAR][START_SMILES]'\n",
    "prompt = tokenizer(prompt, return_tensors=\"pt\").to(device).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.generate(prompt, do_sample=False, max_new_tokens=300, eos_token_id=20, return_dict_in_generate=True, output_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SIMILAR]CC(=O)NC1=CC=C(C=C1)S(=O)(=O)NC2=CC=CC=C2OC 0.9[/SIMILAR][START_SMILES]CC(=O)NC1=CC=C(C=C1)S(=O)(=O)NC2=CC=CC=C2OC[END_SMILES]']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(out.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SIMILAR]COc1ccccc1NS(=O)(=O)c1ccc(NC(C)=O)cc1 0.9[/SIMILAR][START_SMILES]COC1=NS(=O)(=O)N[C@@H]1NC(=O)C=C[END_SMILES]']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(out.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4305555555555556"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_tanimoto_distance('CC(=O)NC1=CC=C(C=C1)S(=O)(=O)NC2=CC=CC=C2OC','COC1=NS(=O)(=O)N[C@@H]1NC(=O)C=C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles('CC(=O)NC1=CC=C(C=C1)S(=O)(=O)NC2=CC=CC=C2OC')\n",
    "mol = Chem.MolToSmiles(mol, isomericSmiles=False, canonical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COc1ccccc1NS(=O)(=O)c1ccc(NC(C)=O)cc1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemlactica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
